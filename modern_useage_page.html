<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Modern GPU Uses</title>
    <link rel="stylesheet" type="text/css" href="css/modern_useage.css" />
</head>
<body>
  <div class="header">
        <h1>Modern GPU Uses</h1>
  </div>

  <div class="navbar">
      <a href="index.html">Home</a>
      <a href="gpu_design_page.html">Modern Day GPU Design</a>
      <a href="gpu_vs_risc_page.html">GPU vs RISC</a>
      <a href="isa_page.html">ISA</a>
      <a href="computing_power_page.html">Computing Power</a>
      <a href="modern_useage_page.html">Modern Uses</a>
      <a href="citations_page.html" class="right">Citations</a>
  </div>

  <div class="content">
    <p>
        The GPUs can process many pieces of data simultaneously, making them useful for machine learning, video editing,
        and gaming. In the 1990s GPUs were used primarily to accelerate real-time 3D graphics applications, such as
        video games. However, as the 21st century began, computer scientists realized that GPUs had the potential to solve
        some of the world’s most difficult computing problems and this has led now to the general purpose GPU era.
    </p>
    <p>
        Today’s GPUs are more programmable than ever before, affording them the flexibility to accelerate a broad range
        of applications that go well beyond traditional graphics rendering.
    </p>
    <h2>
        Video Games
    </h2>
    <p>
        More recently in the 21st Century video games have become more computationally intensive, with hyper realistic
        graphics and vast, complicated in-game worlds. With advanced display technologies, such as 4K screens and high
        refresh rates, along with the rise of virtual reality gaming, demands on graphics processing are growing fast.
        This has made GPUs capable of rendering graphics in both 2D and 3D with better graphics performance, games can be
        played at higher resolution, at faster frame rates, or both.
    </p>
    <h2>
        Machine Learning
    </h2>
    <p>
        Machine Learning makes computers get into a self-learning mode without explicit programming. Some of the most
        exciting applications for GPU technology involve machine learning. Many machine learning applications require
        large amounts of matrix-matrix calculations which the graphics processing units excel at. The amount of
        computational capability  that is incorporated by GPUs allows for them to deliver incredible acceleration in
        workloads that take advantage of the highly parallel nature of GPUs, such as image recognition. Many of today’s
        deep learning technologies rely on GPUs working in conjunction with CPUs
    </p>
    <h2>
        Parallel Programming
    </h2>
    <p>
        Since graphics processing units are inherently parallel in nature it is not surprising that they are used for
        parallel programming. Nvidia has developed CUDA for just this purpose. CUDA extends C/C++ to exploit the large
        parallel computing capabilities of their graphics cards. CUDA has been used to help developers make computer
        intensive applications run faster by exploiting the power of GPUs for parallelize part of computation. The ability
        to program the GPU for parallel tasks has been utilized across many domains including data processing, linear
        algebra, sorting, and physical models among others.
    </p>
  </div>

</body>
</html>
